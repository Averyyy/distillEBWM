{"model_path": "/work/hdd/bdta/distillEBWM/checkpoints/gpt2-small", "ckpt_name": null, "model_type": "gpt2", "teacher_model_type": null, "n_gpu": 1, "n_nodes": 1, "teacher_model_path": null, "teacher_ckpt_name": null, "teacher_model_fp16": false, "model_parallel": false, "model_parallel_size": null, "no_value": false, "dropout_path_rate": null, "fp32": false, "type": null, "do_train": false, "do_valid": false, "do_eval": false, "base_path": null, "load": null, "save": "/u/aqian1/research/distillEBWM/output", "log_interval": 10, "mid_log_num": 4, "save_interval": 1000, "eval_interval": 1000, "local_rank": 0, "save_additional_suffix": "", "save_rollout": false, "eb_sample_times": 3, "data_dir": "/work/hdd/bdta/distillEBWM/data", "processed_data_dir": null, "force_process": false, "force_process_demo": false, "data_process_workers": -1, "train_num": -1, "train_ratio": 1, "dev_num": -1, "dev_ratio": 1, "gen_num": -1, "data_names": null, "prompt_type": null, "num_workers": 1, "max_prompt_length": 512, "min_prompt_length": 128, "json_data": false, "bin_data": false, "txt_data": false, "prompt_data_dir": null, "lm_data_dir": null, "eval_ppl": false, "eval_rw": false, "eval_gen": false, "only_prompt": false, "batch_size": 32, "eval_batch_size": 32, "clip_grad": 1.0, "total_iters": null, "train_iters_per_epoch": -1, "max_length": 1024, "seed": 1234, "seed_order": 42, "seed_data": 42, "seed_ppo": 42, "seed_lm": 7, "epochs": null, "training_epochs": 10000, "gradient_accumulation_steps": 1, "gradient_checkpointing": false, "attn_dtype": null, "lr": null, "lr_min": 1e-07, "weight_decay": 0.01, "loss_scale": 65536, "kd_ratio": null, "warmup_iters": 0, "lr_decay_iters": null, "lr_decay_style": "noam", "scheduler_name": "constant_trm", "reward_scaling": null, "cliprange_reward": 1, "ppo_epochs": null, "num_rollouts": 256, "num_rollouts_per_device": null, "cliprange": 0.2, "chunk_size": null, "gamma": 0.95, "length_norm": false, "single_step_reg": false, "teacher_mixed_alpha": null, "lm_coef": 1, "skew_alpha": 0.1, "student_gen": false, "gen_top_p": 1.0, "gen_num_beams": 2, "mixed_alpha": 0.5, "loss_eps": 0.1, "init_threshold": 0.0, "capacity": 1000, "replay_ratio": "decreasing", "top_k": 0, "top_p": 1.0, "do_sample": false, "no_repeat_ngram_size": 6, "repetition_penalty": null, "num_beams": 1, "temperature": 1, "peft": null, "peft_lora_r": 16, "peft_lora_alpha": 64, "peft_lora_dropout": 0.1, "peft_name": null, "peft_path": null, "teacher_peft_name": null, "teacher_peft_path": null, "deepspeed": false, "deepspeed_config": "/u/aqian1/research/distillEBWM/test_config.json", "deepscale": false, "deepscale_config": null, "rank": 0, "world_size": 1}